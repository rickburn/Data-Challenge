# Lending Club ML Pipeline Configuration
# This file defines all configuration parameters for the pipeline
# following cursor rules standards for externalized configuration

# =============================================================================
# DATA CONFIGURATION
# =============================================================================
data:
  # Data input/output directories
  input_directory: "data/"
  output_directory: "outputs/"
  
  # Quarterly data splits for temporal validation
  train_quarters: 
    - "2016Q1"
    - "2016Q2" 
    - "2016Q3"
  validation_quarter: "2016Q4"
  backtest_quarter: "2017Q1"
  
  # Data processing parameters
  max_missing_rate: 0.50  # Maximum missing value rate per column
  max_duplicate_rate: 0.01  # Maximum duplicate row rate
  min_quality_score: 0.70  # Minimum overall data quality score (realistic for lending data)
  
  # Date column configuration
  date_column: "issue_d"
  date_format: "%Y-%m-%d"

# =============================================================================
# FEATURE ENGINEERING CONFIGURATION  
# =============================================================================
features:
  # Feature selection parameters
  max_features: 50  # Maximum number of features to use
  include_text_features: false  # Whether to create text-derived features
  
  # Missing value handling strategy
  missing_value_strategy: "median"  # Options: median, mean, mode, drop
  
  # Feature scaling method
  scaling_method: "standard"  # Options: standard, minmax, robust
  
  # Feature categories to include
  feature_categories:
    loan_characteristics: true
    borrower_attributes: true 
    credit_history: true
    derived_features: true
    
  # Prohibited features (listing-time compliance)
  prohibited_patterns:
    - ".*pymnt.*"
    - ".*rec_.*" 
    - "chargeoff.*"
    - "settlement.*"
    - "collection.*"
    - "recovery.*"
    
  prohibited_fields:
    - "loan_status"
    - "last_pymnt_d"
    - "last_pymnt_amnt"
    - "next_pymnt_d"
    - "total_rec_prncp"
    - "total_rec_int"
    - "recoveries"
    - "collection_recovery_fee"
    - "out_prncp"
    - "out_prncp_inv"

# Temporal target configuration (CRITICAL FIX for listing-time compliance)
temporal_targets:
  enabled: true  # Enable proper temporal target creation
  observation_windows:
    train: 12      # Minimum 12 months between listing and outcome for training
    validation: 6  # Minimum 6 months for validation
    backtest: 3    # Minimum 3 months for backtest (limited data availability)

  outcome_quarters:
    train: ["2017Q1", "2017Q2", "2017Q3", "2017Q4"]      # Outcomes for 2016Q1-Q3 listings
    validation: ["2017Q2", "2017Q3", "2017Q4"]           # Outcomes for 2016Q4 listings
    backtest: ["2017Q3", "2017Q4"]                       # Outcomes for 2017Q1 listings

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
model:
  # Model type selection
  type: "logistic"  # Options: logistic, random_forest, xgboost, lightgbm
  
  # Reproducibility
  random_state: 42
  
  # Probability calibration
  calibration_method: "platt"  # Options: platt, isotonic
  enable_calibration: true
  
  # Hyperparameter optimization
  hyperparameter_search: true
  cv_folds: 5
  search_iterations: 100
  
  # Model-specific parameters
  logistic_regression:
    C: 1.0
    penalty: "l2"
    solver: "lbfgs"
    max_iter: 1000
    
  random_forest:
    n_estimators: 100
    max_depth: 10
    min_samples_split: 2
    min_samples_leaf: 1
    
  xgboost:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    # GPU settings (uncomment to enable GPU training)
    # tree_method: "gpu_hist"
    # predictor: "gpu_predictor"
    # gpu_id: 0

  lightgbm:
    n_estimators: 100
    max_depth: -1
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    num_leaves: 31
    # GPU settings (uncomment to enable GPU training)
    # device: "gpu"
    # gpu_device_id: 0

  # Hardware and performance settings
  hardware:
    # CPU settings
    n_jobs: -1  # -1 uses all available cores
    max_threads: 8  # Maximum threads for hyperparameter search

    # GPU settings (set use_gpu: true to enable)
    use_gpu: false  # Enable GPU acceleration if available
    gpu_memory_limit: 0.8  # Fraction of GPU memory to use (0.0-1.0)

    # To enable GPU acceleration:
    # 1. Set use_gpu: true
    # 2. Uncomment GPU settings in xgboost/lightgbm sections above
    # 3. Install GPU versions: pip install xgboost[cu11] lightgbm[gpu]
    # 4. Ensure CUDA is installed and configured

    # Memory settings
    max_batch_size: 10000  # Maximum batch size for processing
    memory_efficient: true  # Use memory-efficient processing

  # Performance thresholds
  min_roc_auc: 0.65
  max_brier_score: 0.20
  min_calibration_pvalue: 0.05

# =============================================================================
# INVESTMENT DECISION CONFIGURATION
# =============================================================================
investment:
  # Budget constraints
  budget_per_quarter: 5000.0  # Available investment budget
  
  # Selection strategy
  selection_strategy: "lowest_risk"  # Options: lowest_risk, highest_expected_value, balanced_portfolio
  
  # Risk parameters
  max_default_probability: 0.95  # Maximum acceptable default probability (relaxed for synthetic data)
  min_expected_return: -0.50  # Minimum expected return rate (relaxed for synthetic data)
  
  # Portfolio diversification
  max_concentration_per_grade: 0.30  # Maximum allocation per loan grade
  min_loan_diversity: 1  # Minimum number of loans in portfolio (relaxed for synthetic data)
  
  # ROI calculation method
  roi_calculation_method: "simple"  # Options: simple, detailed
  default_recovery_rate: 0.30  # Expected recovery rate on defaults

# =============================================================================
# EVALUATION AND BACKTESTING CONFIGURATION
# =============================================================================
evaluation:
  # Required evaluation metrics
  required_metrics:
    - "roc_auc"
    - "brier_score" 
    - "calibration_slope"
    - "calibration_intercept"
    - "expected_calibration_error"
    
  # Cross-validation parameters
  cv_method: "temporal"  # Use time-series cross-validation
  cv_splits: 3
  
  # Calibration evaluation
  calibration_bins: 10
  reliability_curve: true
  
  # Backtesting parameters
  backtest_metrics:
    - "default_rate_comparison"
    - "roi_proxy"
    - "sharpe_ratio"
    - "maximum_drawdown"
    
  # Performance benchmarks
  benchmarks:
    random_selection: true
    market_average: true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  # Logging level
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR
  
  # Log directory structure
  log_directory: "logs/"
  
  # Specific log files
  log_files:
    main: "pipeline_execution.log"
    data_operations: "operations/data_operations.jsonl"
    model_training: "operations/model_training.jsonl"
    performance: "performance/performance_metrics.jsonl"
    data_lineage: "data_lineage.jsonl"
    
  # Logging features
  enable_data_lineage: true
  enable_performance_monitoring: true
  enable_json_logging: true
  
  # Log rotation
  max_log_size_mb: 100
  backup_count: 5

# =============================================================================
# PROGRESS TRACKING CONFIGURATION
# =============================================================================
progress:
  # Progress bar settings
  enable_progress_bars: true
  enable_nested_progress: true
  
  # Progress update frequency
  update_frequency: 10  # Update every N steps
  checkpoint_frequency: 50  # Create checkpoint every N steps
  
  # ETA calculation
  eta_window_size: 100  # Number of recent steps for ETA calculation
  
  # Performance monitoring
  enable_memory_tracking: true
  enable_timing_detailed: true

# =============================================================================
# VALIDATION CONFIGURATION  
# =============================================================================
validation:
  # Data quality thresholds
  max_missing_rate: 0.50
  max_duplicate_rate: 0.01
  min_quality_score: 0.70  # Realistic for lending data with expected missing values
  max_outlier_rate: 0.05
  
  # Temporal validation
  enforce_temporal_constraints: true
  allow_date_gaps: true
  min_gap_days: 1
  
  # Feature validation
  enforce_listing_time_rule: true
  strict_feature_compliance: true
  
  # Model validation
  enforce_performance_thresholds: true
  require_calibration: true

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
output:
  # Output directories
  models_directory: "outputs/models/"
  figures_directory: "outputs/figures/"
  reports_directory: "outputs/reports/"
  data_directory: "outputs/data/"
  
  # Output formats
  figure_format: "png"  # Options: png, svg, pdf
  figure_dpi: 300
  report_format: "html"  # Options: html, markdown
  
  # Model artifacts
  save_model_artifacts: true
  save_feature_importance: true
  save_calibration_curves: true
  save_evaluation_plots: true
  
  # Data artifacts
  save_processed_data: true
  save_feature_matrix: false  # Can be large
  save_predictions: true
  
  # Naming conventions
  timestamp_format: "%Y-%m-%d_%H-%M-%S"
  include_git_hash: true

# =============================================================================
# PERFORMANCE AND RESOURCE CONFIGURATION
# =============================================================================
performance:
  # Computational limits
  max_memory_gb: 16
  max_execution_time_minutes: 60
  
  # Processing parameters
  chunk_size: 10000  # For large dataset processing
  n_jobs: -1  # Number of parallel jobs (-1 for all cores)
  
  # Caching
  enable_caching: true
  cache_directory: ".cache/"
  
  # Performance targets
  target_data_loading_time: 30  # seconds
  target_feature_engineering_time: 300  # seconds  
  target_model_training_time: 1800  # seconds
  target_prediction_time: 10  # seconds

# =============================================================================
# DEVELOPMENT AND TESTING CONFIGURATION
# =============================================================================
development:
  # Debug settings
  debug_mode: false
  verbose_logging: false
  
  # Testing
  enable_unit_tests: true
  enable_integration_tests: true
  test_data_size: 1000  # Rows for testing
  
  # Development aids
  enable_profiling: false
  enable_memory_profiling: false
  
  # Code quality
  enforce_type_hints: true
  enforce_docstrings: true
  max_line_length: 100
  
# =============================================================================
# ENVIRONMENT CONFIGURATION
# =============================================================================
environment:
  # Python requirements
  python_version: "3.9"
  
  # Package versions (pinned for reproducibility)
  package_versions:
    pandas: "1.5.0"
    numpy: "1.21.0"
    scikit_learn: "1.1.0"
    matplotlib: "3.5.0"
    seaborn: "0.11.0"
    tqdm: "4.64.0"
    
  # Optional packages
  optional_packages:
    xgboost: "1.6.0"
    lightgbm: "3.3.0"
    psutil: "5.9.0"
    
  # System requirements
  min_memory_gb: 8
  min_cpu_cores: 4
  min_disk_space_gb: 10

# =============================================================================
# SECURITY AND COMPLIANCE CONFIGURATION
# =============================================================================
security:
  # Data protection
  encrypt_logs: false  # For local development
  encrypt_models: false
  
  # Access control
  restrict_file_permissions: true
  
  # Audit and compliance
  enable_audit_logging: true
  track_data_access: true
  
  # Privacy
  anonymize_logs: false  # No PII expected
  data_retention_days: 90

# =============================================================================
# METADATA AND DOCUMENTATION CONFIGURATION
# =============================================================================
metadata:
  # Project information
  project_name: "Lending Club ML Pipeline"
  project_version: "1.0.0"
  
  # Documentation
  auto_generate_docs: true
  include_model_cards: true
  include_data_dictionary: true
  
  # Versioning
  track_model_versions: true
  track_data_versions: true
  track_config_versions: true
